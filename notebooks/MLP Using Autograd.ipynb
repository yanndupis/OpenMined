{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import syft\n",
    "import syft.nn as nn\n",
    "from syft.controller import tensors, models\n",
    "import imp\n",
    "imp.reload(syft.controller)\n",
    "imp.reload(syft.nn)\n",
    "imp.reload(syft)\n",
    "\n",
    "import numpy as np\n",
    "from syft import FloatTensor\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = FloatTensor([[0,0,1],[0,1.0,1],[1,0,1],[1,1,1]], autograd=True)\n",
    "target = FloatTensor([[0],[0],[1],[1]]).autograd(True)\n",
    "grad = FloatTensor([[1],[1],[1],[1]]).autograd(False)\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "weights1 = FloatTensor(np.random.rand(3,4)).autograd(True)\n",
    "weights2 = FloatTensor(np.random.rand(4,1)).autograd(True)\n",
    "\n",
    "input_t = Variable(torch.FloatTensor(input.to_numpy()), requires_grad=True)\n",
    "target_t = Variable(torch.FloatTensor(target.to_numpy()), requires_grad=True)\n",
    "weights1_t = Variable(torch.FloatTensor(weights1.to_numpy()), requires_grad=True)\n",
    "weights2_t = Variable(torch.FloatTensor(weights2.to_numpy()), requires_grad=True)\n",
    "\n",
    "grad_t = Variable(torch.FloatTensor(grad.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.4170  0.7203  0.0001  0.3023\n",
       " 0.1468  0.0923  0.1863  0.3456\n",
       " 0.3968  0.5388  0.4192  0.6852\n",
       "[torch.FloatTensor of size 3x4]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights1_t.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.2045\n",
       " 0.8781\n",
       " 0.0274\n",
       " 0.6705\n",
       "[torch.FloatTensor of size 4x1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights2_t.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "1.00000e-02 *\n",
       " -0.5600 -1.9540 -0.0849 -1.6177\n",
       "  1.0343  4.5097  0.1307  2.8359\n",
       "  2.1014  9.1505  0.2678  6.0765\n",
       "[torch.FloatTensor of size 3x4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights1_t.grad = None\n",
    "weights2_t.grad = None\n",
    "target_t.grad = None\n",
    "input_t.grad = None\n",
    "\n",
    "layer_1_t = input_t.mm(weights1_t).sigmoid()\n",
    "layer_2_t = layer_1_t.mm(weights2_t).sigmoid()\n",
    "\n",
    "diff_t = layer_2_t - target_t\n",
    "loss_t = diff_t ** 2\n",
    "loss_t.backward(grad_t)\n",
    "\n",
    "#print(loss_t.sum().data[0])\n",
    "\n",
    "weights1_t.data -= weights1_t.grad.data\n",
    "weights2_t.data -= weights2_t.grad.data\n",
    "weights1_t.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.2449\n",
       " 0.2493\n",
       " 0.2613\n",
       " 0.2852\n",
       "[torch.FloatTensor of size 4x1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights2_t.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_1 = input.mm(weights1).sigmoid()\n",
    "layer_2 = layer_1.mm(weights2).sigmoid()\n",
    "\n",
    "diff = (layer_2 - target)\n",
    "loss = diff ** 2 # Mean Squared Error Loss\n",
    "\n",
    "loss.backward(grad)\n",
    "weights1 -= weights1.grad()\n",
    "weights2 -= weights2.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.00559968 -0.01954043 -0.00084936 -0.01617729]\n",
       " [ 0.01034258  0.04509664  0.00130671  0.02835879]\n",
       " [ 0.02101371  0.09150549  0.00267767  0.06076522]]\n",
       "[syft.FloatTensor:72 grad:None size:3x4 c:[] p:[70, 68] init:mm]\n",
       "\n",
       "\t-----------creators-----------\n",
       "\t[syft.FloatTensor:70 grad:None size:3x4 c:[72] p:[38] init:transpose]\n",
       "\t[syft.FloatTensor:68 grad:None size:4x4 c:[71, 72] p:[67, 62] init:mul_elem]\n",
       "\t------------------------------\n",
       "\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights1.grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[ 0.244891 ]\n",
       " [ 0.249277 ]\n",
       " [ 0.2613002]\n",
       " [ 0.2851809]]\n",
       "[syft.FloatTensor:73 grad:None size:4x1 c:[] p:[61, 59] init:mm]\n",
       "\n",
       "\t-----------creators-----------\n",
       "\t[syft.FloatTensor:61 grad:None size:4x4 c:[73] p:[44] init:transpose]\n",
       "\t[syft.FloatTensor:59 grad:None size:4x1 c:[62, 73] p:[58, 53] init:mul_elem]\n",
       "\t------------------------------\n",
       "\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights2.grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = FloatTensor([[0,0,1],[0,1.0,1],[1,0,1],[1,1,1]], autograd=True)\n",
    "target = FloatTensor([[0],[0],[1],[1]]).autograd(True)\n",
    "grad = FloatTensor([[1],[1],[1],[1]]).autograd(False)\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "weights1 = FloatTensor(np.random.rand(3,4)).autograd(True)\n",
    "weights2_data = np.array([0.2044522,0.8781174,-0.02738759,-0.6704675])\n",
    "weights2_data.shape = (4,1)\n",
    "weights2 = FloatTensor(weights2_data).autograd(True)\n",
    "\n",
    "input_t = Variable(torch.FloatTensor(input.to_numpy()), requires_grad=True)\n",
    "target_t = Variable(torch.FloatTensor(target.to_numpy()), requires_grad=True)\n",
    "weights1_t = Variable(torch.FloatTensor(weights1.to_numpy()), requires_grad=True)\n",
    "weights2_t = Variable(torch.FloatTensor(weights2.to_numpy()), requires_grad=True)\n",
    "\n",
    "grad_t = Variable(torch.FloatTensor(grad.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[ 0.2044522 ]\n",
       " [ 0.8781174 ]\n",
       " [-0.02738759]\n",
       " [-0.6704675 ]]\n",
       "[syft.FloatTensor:254 grad:None size:4x1 c:[] p:[] init:]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer2 before relu:\n",
      "Variable containing:\n",
      " 0.0834\n",
      "-0.0423\n",
      " 0.5984\n",
      " 0.4727\n",
      "[torch.FloatTensor of size 4x1]\n",
      "\n",
      "Layer2 after relu:\n",
      "Variable containing:\n",
      " 0.0834\n",
      " 0.0000\n",
      " 0.5984\n",
      " 0.4727\n",
      "[torch.FloatTensor of size 4x1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.3798 -1.6312  0.0509  1.2455\n",
       "-0.2156 -0.9260  0.0289  0.7070\n",
       "-0.3457 -1.4848  0.0463  1.1337\n",
       "[torch.FloatTensor of size 3x4]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights1_t.grad = None\n",
    "weights2_t.grad = None\n",
    "target_t.grad = None\n",
    "input_t.grad = None\n",
    "\n",
    "layer_1_t = input_t.mm(weights1_t).clamp(min=0)\n",
    "layer_2_t = layer_1_t.mm(weights2_t).clamp(min=0)\n",
    "\n",
    "print(\"Layer2 before relu:\")\n",
    "print(layer_1_t.mm(weights2_t))\n",
    "print(\"Layer2 after relu:\")\n",
    "print(layer_2_t)\n",
    "\n",
    "diff_t = layer_2_t - target_t\n",
    "loss_t = diff_t ** 2\n",
    "loss_t.backward(grad_t)\n",
    "\n",
    "#print(loss_t.sum().data[0])\n",
    "\n",
    "weights1_t.data -= weights1_t.grad.data\n",
    "weights2_t.data -= weights2_t.grad.data\n",
    "weights1_t.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-1.6003\n",
       "-2.3465\n",
       "-0.9054\n",
       "-2.0846\n",
       "[torch.FloatTensor of size 4x1]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights2_t.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer2 before relu:\n",
      "   0.0833662  \n",
      "  -0.04233359 \n",
      "   0.5984493  \n",
      "   0.4727495   \n",
      "\n",
      "Layer2 after relu:\n",
      "   0.0833662 \n",
      "   0.        \n",
      "   0.5984493 \n",
      "   0.4727495  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "layer_1 = input.mm(weights1).relu()\n",
    "layer_2 = layer_1.mm(weights2).relu()\n",
    "\n",
    "print(\"Layer2 before relu:\")\n",
    "print(layer_1.mm(weights2))\n",
    "print(\"Layer2 after relu:\")\n",
    "print(layer_2)\n",
    "\n",
    "diff = (layer_2 - target)\n",
    "loss = diff ** 2 # Mean Squared Error Loss\n",
    "\n",
    "loss.backward(grad)\n",
    "weights1 -= weights1.grad()\n",
    "weights2 -= weights2.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.3797909  -1.631193    0.05087525  1.245462  ]\n",
       " [-0.2155951  -0.9259757   0.02888024  0.7070087 ]\n",
       " [-0.3457021  -1.484782    0.04630886  1.133673  ]]\n",
       "[syft.FloatTensor:278 grad:None size:3x4 c:[] p:[276, 274] init:mm]\n",
       "\n",
       "\t-----------creators-----------\n",
       "\t[syft.FloatTensor:276 grad:None size:3x4 c:[278] p:[250] init:transpose]\n",
       "\t[syft.FloatTensor:274 grad:None size:4x4 c:[277, 278] p:[273, 271] init:mul_elem]\n",
       "\t------------------------------\n",
       "\n"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights1.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1.600298 ]\n",
       " [-2.346517 ]\n",
       " [-0.9054275]\n",
       " [-2.084625 ]]\n",
       "[syft.FloatTensor:279 grad:None size:4x1 c:[] p:[270, 268] init:mm]\n",
       "\n",
       "\t-----------creators-----------\n",
       "\t[syft.FloatTensor:270 grad:None size:4x4 c:[279] p:[256] init:transpose]\n",
       "\t[syft.FloatTensor:268 grad:None size:4x1 c:[271, 279] p:[267, 264] init:mul_elem]\n",
       "\t------------------------------\n",
       "\n"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights2.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
